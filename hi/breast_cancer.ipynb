{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd04ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b44705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec90e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ebf317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac76fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e26b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data=to_categorical(df['label'])\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af3bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = df.iloc[:,:-1]\n",
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee7b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d5dcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
       "        0.41886396],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
       "        0.22287813],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
       "        0.21343303],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
       "        0.1519087 ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
       "        0.45231536],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
       "        0.10068215]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_data_scaled = scaler.fit_transform(X_data)\n",
    "X_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caac79dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 30) (512, 2)\n",
      "(57, 30) (57, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data_scaled, y_data, \n",
    "                                                    test_size=0.1, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=11)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "098e9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3e716d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()##Layer 쌓을 수 있도록 객체를 생성 \n",
    "model.add(Dense(128, activation='relu', input_dim=30))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "303b35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               3968      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,162\n",
      "Trainable params: 8,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc','mae'])\n",
    "#이 모델로 설정을 하겠음.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64b601ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "16/16 - 1s - loss: 0.6752 - acc: 0.6172 - mae: 0.4265 - 514ms/epoch - 32ms/step\n",
      "Epoch 2/300\n",
      "16/16 - 0s - loss: 0.6025 - acc: 0.6680 - mae: 0.3962 - 25ms/epoch - 2ms/step\n",
      "Epoch 3/300\n",
      "16/16 - 0s - loss: 0.5539 - acc: 0.8691 - mae: 0.3523 - 26ms/epoch - 2ms/step\n",
      "Epoch 4/300\n",
      "16/16 - 0s - loss: 0.4955 - acc: 0.8965 - mae: 0.2944 - 28ms/epoch - 2ms/step\n",
      "Epoch 5/300\n",
      "16/16 - 0s - loss: 0.4324 - acc: 0.8965 - mae: 0.2376 - 24ms/epoch - 2ms/step\n",
      "Epoch 6/300\n",
      "16/16 - 0s - loss: 0.3718 - acc: 0.9160 - mae: 0.1909 - 27ms/epoch - 2ms/step\n",
      "Epoch 7/300\n",
      "16/16 - 0s - loss: 0.3234 - acc: 0.9102 - mae: 0.1598 - 27ms/epoch - 2ms/step\n",
      "Epoch 8/300\n",
      "16/16 - 0s - loss: 0.2864 - acc: 0.9336 - mae: 0.1358 - 24ms/epoch - 1ms/step\n",
      "Epoch 9/300\n",
      "16/16 - 0s - loss: 0.2565 - acc: 0.9199 - mae: 0.1204 - 24ms/epoch - 2ms/step\n",
      "Epoch 10/300\n",
      "16/16 - 0s - loss: 0.2368 - acc: 0.9277 - mae: 0.1094 - 26ms/epoch - 2ms/step\n",
      "Epoch 11/300\n",
      "16/16 - 0s - loss: 0.2207 - acc: 0.9336 - mae: 0.1006 - 23ms/epoch - 1ms/step\n",
      "Epoch 12/300\n",
      "16/16 - 0s - loss: 0.2019 - acc: 0.9395 - mae: 0.0915 - 26ms/epoch - 2ms/step\n",
      "Epoch 13/300\n",
      "16/16 - 0s - loss: 0.1881 - acc: 0.9414 - mae: 0.0853 - 27ms/epoch - 2ms/step\n",
      "Epoch 14/300\n",
      "16/16 - 0s - loss: 0.1804 - acc: 0.9473 - mae: 0.0814 - 28ms/epoch - 2ms/step\n",
      "Epoch 15/300\n",
      "16/16 - 0s - loss: 0.1691 - acc: 0.9512 - mae: 0.0761 - 25ms/epoch - 2ms/step\n",
      "Epoch 16/300\n",
      "16/16 - 0s - loss: 0.1575 - acc: 0.9531 - mae: 0.0700 - 22ms/epoch - 1ms/step\n",
      "Epoch 17/300\n",
      "16/16 - 0s - loss: 0.1513 - acc: 0.9590 - mae: 0.0671 - 26ms/epoch - 2ms/step\n",
      "Epoch 18/300\n",
      "16/16 - 0s - loss: 0.1456 - acc: 0.9531 - mae: 0.0636 - 27ms/epoch - 2ms/step\n",
      "Epoch 19/300\n",
      "16/16 - 0s - loss: 0.1355 - acc: 0.9570 - mae: 0.0586 - 27ms/epoch - 2ms/step\n",
      "Epoch 20/300\n",
      "16/16 - 0s - loss: 0.1309 - acc: 0.9648 - mae: 0.0568 - 25ms/epoch - 2ms/step\n",
      "Epoch 21/300\n",
      "16/16 - 0s - loss: 0.1228 - acc: 0.9707 - mae: 0.0515 - 29ms/epoch - 2ms/step\n",
      "Epoch 22/300\n",
      "16/16 - 0s - loss: 0.1197 - acc: 0.9727 - mae: 0.0499 - 21ms/epoch - 1ms/step\n",
      "Epoch 23/300\n",
      "16/16 - 0s - loss: 0.1119 - acc: 0.9727 - mae: 0.0463 - 21ms/epoch - 1ms/step\n",
      "Epoch 24/300\n",
      "16/16 - 0s - loss: 0.1086 - acc: 0.9727 - mae: 0.0445 - 20ms/epoch - 1ms/step\n",
      "Epoch 25/300\n",
      "16/16 - 0s - loss: 0.1037 - acc: 0.9785 - mae: 0.0411 - 26ms/epoch - 2ms/step\n",
      "Epoch 26/300\n",
      "16/16 - 0s - loss: 0.1025 - acc: 0.9707 - mae: 0.0430 - 26ms/epoch - 2ms/step\n",
      "Epoch 27/300\n",
      "16/16 - 0s - loss: 0.0976 - acc: 0.9707 - mae: 0.0384 - 27ms/epoch - 2ms/step\n",
      "Epoch 28/300\n",
      "16/16 - 0s - loss: 0.0943 - acc: 0.9746 - mae: 0.0379 - 25ms/epoch - 2ms/step\n",
      "Epoch 29/300\n",
      "16/16 - 0s - loss: 0.0913 - acc: 0.9746 - mae: 0.0367 - 25ms/epoch - 2ms/step\n",
      "Epoch 30/300\n",
      "16/16 - 0s - loss: 0.0939 - acc: 0.9746 - mae: 0.0365 - 24ms/epoch - 1ms/step\n",
      "Epoch 31/300\n",
      "16/16 - 0s - loss: 0.0876 - acc: 0.9785 - mae: 0.0341 - 27ms/epoch - 2ms/step\n",
      "Epoch 32/300\n",
      "16/16 - 0s - loss: 0.0851 - acc: 0.9785 - mae: 0.0335 - 27ms/epoch - 2ms/step\n",
      "Epoch 33/300\n",
      "16/16 - 0s - loss: 0.0822 - acc: 0.9824 - mae: 0.0312 - 28ms/epoch - 2ms/step\n",
      "Epoch 34/300\n",
      "16/16 - 0s - loss: 0.0789 - acc: 0.9805 - mae: 0.0298 - 28ms/epoch - 2ms/step\n",
      "Epoch 35/300\n",
      "16/16 - 0s - loss: 0.0776 - acc: 0.9805 - mae: 0.0294 - 27ms/epoch - 2ms/step\n",
      "Epoch 36/300\n",
      "16/16 - 0s - loss: 0.0771 - acc: 0.9766 - mae: 0.0300 - 27ms/epoch - 2ms/step\n",
      "Epoch 37/300\n",
      "16/16 - 0s - loss: 0.0756 - acc: 0.9824 - mae: 0.0275 - 25ms/epoch - 2ms/step\n",
      "Epoch 38/300\n",
      "16/16 - 0s - loss: 0.0759 - acc: 0.9824 - mae: 0.0291 - 27ms/epoch - 2ms/step\n",
      "Epoch 39/300\n",
      "16/16 - 0s - loss: 0.0798 - acc: 0.9707 - mae: 0.0335 - 25ms/epoch - 2ms/step\n",
      "Epoch 40/300\n",
      "16/16 - 0s - loss: 0.0910 - acc: 0.9648 - mae: 0.0415 - 26ms/epoch - 2ms/step\n",
      "Epoch 41/300\n",
      "16/16 - 0s - loss: 0.0744 - acc: 0.9805 - mae: 0.0290 - 25ms/epoch - 2ms/step\n",
      "Epoch 42/300\n",
      "16/16 - 0s - loss: 0.0667 - acc: 0.9824 - mae: 0.0237 - 25ms/epoch - 2ms/step\n",
      "Epoch 43/300\n",
      "16/16 - 0s - loss: 0.0688 - acc: 0.9805 - mae: 0.0259 - 26ms/epoch - 2ms/step\n",
      "Epoch 44/300\n",
      "16/16 - 0s - loss: 0.0708 - acc: 0.9805 - mae: 0.0265 - 24ms/epoch - 2ms/step\n",
      "Epoch 45/300\n",
      "16/16 - 0s - loss: 0.0659 - acc: 0.9844 - mae: 0.0238 - 30ms/epoch - 2ms/step\n",
      "Epoch 46/300\n",
      "16/16 - 0s - loss: 0.0649 - acc: 0.9844 - mae: 0.0230 - 28ms/epoch - 2ms/step\n",
      "Epoch 47/300\n",
      "16/16 - 0s - loss: 0.0637 - acc: 0.9785 - mae: 0.0234 - 29ms/epoch - 2ms/step\n",
      "Epoch 48/300\n",
      "16/16 - 0s - loss: 0.0636 - acc: 0.9863 - mae: 0.0223 - 26ms/epoch - 2ms/step\n",
      "Epoch 49/300\n",
      "16/16 - 0s - loss: 0.0625 - acc: 0.9805 - mae: 0.0235 - 27ms/epoch - 2ms/step\n",
      "Epoch 50/300\n",
      "16/16 - 0s - loss: 0.0634 - acc: 0.9844 - mae: 0.0221 - 29ms/epoch - 2ms/step\n",
      "Epoch 51/300\n",
      "16/16 - 0s - loss: 0.0635 - acc: 0.9863 - mae: 0.0226 - 24ms/epoch - 2ms/step\n",
      "Epoch 52/300\n",
      "16/16 - 0s - loss: 0.0608 - acc: 0.9863 - mae: 0.0209 - 23ms/epoch - 1ms/step\n",
      "Epoch 53/300\n",
      "16/16 - 0s - loss: 0.0610 - acc: 0.9824 - mae: 0.0227 - 29ms/epoch - 2ms/step\n",
      "Epoch 54/300\n",
      "16/16 - 0s - loss: 0.0601 - acc: 0.9844 - mae: 0.0215 - 29ms/epoch - 2ms/step\n",
      "Epoch 55/300\n",
      "16/16 - 0s - loss: 0.0601 - acc: 0.9805 - mae: 0.0222 - 29ms/epoch - 2ms/step\n",
      "Epoch 56/300\n",
      "16/16 - 0s - loss: 0.0585 - acc: 0.9844 - mae: 0.0209 - 28ms/epoch - 2ms/step\n",
      "Epoch 57/300\n",
      "16/16 - 0s - loss: 0.0578 - acc: 0.9844 - mae: 0.0207 - 22ms/epoch - 1ms/step\n",
      "Epoch 58/300\n",
      "16/16 - 0s - loss: 0.0573 - acc: 0.9824 - mae: 0.0204 - 25ms/epoch - 2ms/step\n",
      "Epoch 59/300\n",
      "16/16 - 0s - loss: 0.0581 - acc: 0.9805 - mae: 0.0214 - 23ms/epoch - 1ms/step\n",
      "Epoch 60/300\n",
      "16/16 - 0s - loss: 0.0605 - acc: 0.9844 - mae: 0.0218 - 23ms/epoch - 1ms/step\n",
      "Epoch 61/300\n",
      "16/16 - 0s - loss: 0.0557 - acc: 0.9863 - mae: 0.0201 - 29ms/epoch - 2ms/step\n",
      "Epoch 62/300\n",
      "16/16 - 0s - loss: 0.0587 - acc: 0.9824 - mae: 0.0230 - 34ms/epoch - 2ms/step\n",
      "Epoch 63/300\n",
      "16/16 - 0s - loss: 0.0555 - acc: 0.9844 - mae: 0.0202 - 28ms/epoch - 2ms/step\n",
      "Epoch 64/300\n",
      "16/16 - 0s - loss: 0.0622 - acc: 0.9844 - mae: 0.0241 - 30ms/epoch - 2ms/step\n",
      "Epoch 65/300\n",
      "16/16 - 0s - loss: 0.0639 - acc: 0.9746 - mae: 0.0261 - 27ms/epoch - 2ms/step\n",
      "Epoch 66/300\n",
      "16/16 - 0s - loss: 0.0532 - acc: 0.9824 - mae: 0.0202 - 23ms/epoch - 1ms/step\n",
      "Epoch 67/300\n",
      "16/16 - 0s - loss: 0.0551 - acc: 0.9824 - mae: 0.0194 - 25ms/epoch - 2ms/step\n",
      "Epoch 68/300\n",
      "16/16 - 0s - loss: 0.0539 - acc: 0.9863 - mae: 0.0193 - 25ms/epoch - 2ms/step\n",
      "Epoch 69/300\n",
      "16/16 - 0s - loss: 0.0560 - acc: 0.9844 - mae: 0.0204 - 22ms/epoch - 1ms/step\n",
      "Epoch 70/300\n",
      "16/16 - 0s - loss: 0.0534 - acc: 0.9844 - mae: 0.0199 - 26ms/epoch - 2ms/step\n",
      "Epoch 71/300\n",
      "16/16 - 0s - loss: 0.0516 - acc: 0.9863 - mae: 0.0181 - 26ms/epoch - 2ms/step\n",
      "Epoch 72/300\n",
      "16/16 - 0s - loss: 0.0520 - acc: 0.9844 - mae: 0.0197 - 23ms/epoch - 1ms/step\n",
      "Epoch 73/300\n",
      "16/16 - 0s - loss: 0.0520 - acc: 0.9863 - mae: 0.0173 - 24ms/epoch - 2ms/step\n",
      "Epoch 74/300\n",
      "16/16 - 0s - loss: 0.0516 - acc: 0.9863 - mae: 0.0183 - 24ms/epoch - 2ms/step\n",
      "Epoch 75/300\n",
      "16/16 - 0s - loss: 0.0509 - acc: 0.9824 - mae: 0.0189 - 22ms/epoch - 1ms/step\n",
      "Epoch 76/300\n",
      "16/16 - 0s - loss: 0.0519 - acc: 0.9844 - mae: 0.0195 - 28ms/epoch - 2ms/step\n",
      "Epoch 77/300\n",
      "16/16 - 0s - loss: 0.0513 - acc: 0.9844 - mae: 0.0187 - 27ms/epoch - 2ms/step\n",
      "Epoch 78/300\n",
      "16/16 - 0s - loss: 0.0567 - acc: 0.9883 - mae: 0.0203 - 27ms/epoch - 2ms/step\n",
      "Epoch 79/300\n",
      "16/16 - 0s - loss: 0.0486 - acc: 0.9883 - mae: 0.0166 - 23ms/epoch - 1ms/step\n",
      "Epoch 80/300\n",
      "16/16 - 0s - loss: 0.0507 - acc: 0.9863 - mae: 0.0199 - 25ms/epoch - 2ms/step\n",
      "Epoch 81/300\n",
      "16/16 - 0s - loss: 0.0502 - acc: 0.9883 - mae: 0.0172 - 25ms/epoch - 2ms/step\n",
      "Epoch 82/300\n",
      "16/16 - 0s - loss: 0.0588 - acc: 0.9766 - mae: 0.0253 - 28ms/epoch - 2ms/step\n",
      "Epoch 83/300\n",
      "16/16 - 0s - loss: 0.0536 - acc: 0.9883 - mae: 0.0183 - 26ms/epoch - 2ms/step\n",
      "Epoch 84/300\n",
      "16/16 - 0s - loss: 0.0512 - acc: 0.9844 - mae: 0.0192 - 26ms/epoch - 2ms/step\n",
      "Epoch 85/300\n",
      "16/16 - 0s - loss: 0.0490 - acc: 0.9863 - mae: 0.0188 - 23ms/epoch - 1ms/step\n",
      "Epoch 86/300\n",
      "16/16 - 0s - loss: 0.0496 - acc: 0.9863 - mae: 0.0168 - 24ms/epoch - 2ms/step\n",
      "Epoch 87/300\n",
      "16/16 - 0s - loss: 0.0505 - acc: 0.9824 - mae: 0.0203 - 28ms/epoch - 2ms/step\n",
      "Epoch 88/300\n",
      "16/16 - 0s - loss: 0.0487 - acc: 0.9863 - mae: 0.0170 - 28ms/epoch - 2ms/step\n",
      "Epoch 89/300\n",
      "16/16 - 0s - loss: 0.0473 - acc: 0.9863 - mae: 0.0169 - 22ms/epoch - 1ms/step\n",
      "Epoch 90/300\n",
      "16/16 - 0s - loss: 0.0460 - acc: 0.9844 - mae: 0.0173 - 23ms/epoch - 1ms/step\n",
      "Epoch 91/300\n",
      "16/16 - 0s - loss: 0.0482 - acc: 0.9863 - mae: 0.0173 - 24ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/300\n",
      "16/16 - 0s - loss: 0.0472 - acc: 0.9844 - mae: 0.0171 - 26ms/epoch - 2ms/step\n",
      "Epoch 93/300\n",
      "16/16 - 0s - loss: 0.0504 - acc: 0.9805 - mae: 0.0217 - 25ms/epoch - 2ms/step\n",
      "Epoch 94/300\n",
      "16/16 - 0s - loss: 0.0552 - acc: 0.9844 - mae: 0.0187 - 23ms/epoch - 1ms/step\n",
      "Epoch 95/300\n",
      "16/16 - 0s - loss: 0.0508 - acc: 0.9766 - mae: 0.0214 - 26ms/epoch - 2ms/step\n",
      "Epoch 96/300\n",
      "16/16 - 0s - loss: 0.0464 - acc: 0.9883 - mae: 0.0175 - 28ms/epoch - 2ms/step\n",
      "Epoch 97/300\n",
      "16/16 - 0s - loss: 0.0478 - acc: 0.9844 - mae: 0.0168 - 25ms/epoch - 2ms/step\n",
      "Epoch 98/300\n",
      "16/16 - 0s - loss: 0.0453 - acc: 0.9805 - mae: 0.0177 - 27ms/epoch - 2ms/step\n",
      "Epoch 99/300\n",
      "16/16 - 0s - loss: 0.0465 - acc: 0.9863 - mae: 0.0187 - 26ms/epoch - 2ms/step\n",
      "Epoch 100/300\n",
      "16/16 - 0s - loss: 0.0451 - acc: 0.9883 - mae: 0.0157 - 26ms/epoch - 2ms/step\n",
      "Epoch 101/300\n",
      "16/16 - 0s - loss: 0.0497 - acc: 0.9824 - mae: 0.0200 - 26ms/epoch - 2ms/step\n",
      "Epoch 102/300\n",
      "16/16 - 0s - loss: 0.0474 - acc: 0.9883 - mae: 0.0156 - 22ms/epoch - 1ms/step\n",
      "Epoch 103/300\n",
      "16/16 - 0s - loss: 0.0469 - acc: 0.9824 - mae: 0.0206 - 24ms/epoch - 1ms/step\n",
      "Epoch 104/300\n",
      "16/16 - 0s - loss: 0.0464 - acc: 0.9844 - mae: 0.0168 - 26ms/epoch - 2ms/step\n",
      "Epoch 105/300\n",
      "16/16 - 0s - loss: 0.0452 - acc: 0.9863 - mae: 0.0160 - 24ms/epoch - 2ms/step\n",
      "Epoch 106/300\n",
      "16/16 - 0s - loss: 0.0425 - acc: 0.9883 - mae: 0.0160 - 24ms/epoch - 2ms/step\n",
      "Epoch 107/300\n",
      "16/16 - 0s - loss: 0.0431 - acc: 0.9863 - mae: 0.0156 - 25ms/epoch - 2ms/step\n",
      "Epoch 108/300\n",
      "16/16 - 0s - loss: 0.0426 - acc: 0.9883 - mae: 0.0168 - 22ms/epoch - 1ms/step\n",
      "Epoch 109/300\n",
      "16/16 - 0s - loss: 0.0434 - acc: 0.9883 - mae: 0.0178 - 23ms/epoch - 1ms/step\n",
      "Epoch 110/300\n",
      "16/16 - 0s - loss: 0.0508 - acc: 0.9844 - mae: 0.0174 - 23ms/epoch - 1ms/step\n",
      "Epoch 111/300\n",
      "16/16 - 0s - loss: 0.0439 - acc: 0.9902 - mae: 0.0161 - 22ms/epoch - 1ms/step\n",
      "Epoch 112/300\n",
      "16/16 - 0s - loss: 0.0458 - acc: 0.9883 - mae: 0.0180 - 21ms/epoch - 1ms/step\n",
      "Epoch 113/300\n",
      "16/16 - 0s - loss: 0.0480 - acc: 0.9863 - mae: 0.0175 - 22ms/epoch - 1ms/step\n",
      "Epoch 114/300\n",
      "16/16 - 0s - loss: 0.0432 - acc: 0.9863 - mae: 0.0172 - 21ms/epoch - 1ms/step\n",
      "Epoch 115/300\n",
      "16/16 - 0s - loss: 0.0448 - acc: 0.9844 - mae: 0.0174 - 26ms/epoch - 2ms/step\n",
      "Epoch 116/300\n",
      "16/16 - 0s - loss: 0.0413 - acc: 0.9863 - mae: 0.0159 - 23ms/epoch - 1ms/step\n",
      "Epoch 117/300\n",
      "16/16 - 0s - loss: 0.0408 - acc: 0.9883 - mae: 0.0152 - 22ms/epoch - 1ms/step\n",
      "Epoch 118/300\n",
      "16/16 - 0s - loss: 0.0401 - acc: 0.9883 - mae: 0.0145 - 23ms/epoch - 1ms/step\n",
      "Epoch 119/300\n",
      "16/16 - 0s - loss: 0.0417 - acc: 0.9883 - mae: 0.0157 - 24ms/epoch - 1ms/step\n",
      "Epoch 120/300\n",
      "16/16 - 0s - loss: 0.0412 - acc: 0.9863 - mae: 0.0159 - 25ms/epoch - 2ms/step\n",
      "Epoch 121/300\n",
      "16/16 - 0s - loss: 0.0395 - acc: 0.9883 - mae: 0.0155 - 23ms/epoch - 1ms/step\n",
      "Epoch 122/300\n",
      "16/16 - 0s - loss: 0.0392 - acc: 0.9883 - mae: 0.0144 - 21ms/epoch - 1ms/step\n",
      "Epoch 123/300\n",
      "16/16 - 0s - loss: 0.0410 - acc: 0.9883 - mae: 0.0177 - 24ms/epoch - 2ms/step\n",
      "Epoch 124/300\n",
      "16/16 - 0s - loss: 0.0549 - acc: 0.9805 - mae: 0.0227 - 24ms/epoch - 2ms/step\n",
      "Epoch 125/300\n",
      "16/16 - 0s - loss: 0.0478 - acc: 0.9785 - mae: 0.0204 - 28ms/epoch - 2ms/step\n",
      "Epoch 126/300\n",
      "16/16 - 0s - loss: 0.0470 - acc: 0.9844 - mae: 0.0206 - 25ms/epoch - 2ms/step\n",
      "Epoch 127/300\n",
      "16/16 - 0s - loss: 0.0438 - acc: 0.9824 - mae: 0.0175 - 27ms/epoch - 2ms/step\n",
      "Epoch 128/300\n",
      "16/16 - 0s - loss: 0.0415 - acc: 0.9902 - mae: 0.0148 - 25ms/epoch - 2ms/step\n",
      "Epoch 129/300\n",
      "16/16 - 0s - loss: 0.0409 - acc: 0.9883 - mae: 0.0163 - 23ms/epoch - 1ms/step\n",
      "Epoch 130/300\n",
      "16/16 - 0s - loss: 0.0385 - acc: 0.9883 - mae: 0.0148 - 26ms/epoch - 2ms/step\n",
      "Epoch 131/300\n",
      "16/16 - 0s - loss: 0.0383 - acc: 0.9883 - mae: 0.0150 - 25ms/epoch - 2ms/step\n",
      "Epoch 132/300\n",
      "16/16 - 0s - loss: 0.0418 - acc: 0.9824 - mae: 0.0185 - 25ms/epoch - 2ms/step\n",
      "Epoch 133/300\n",
      "16/16 - 0s - loss: 0.0397 - acc: 0.9883 - mae: 0.0149 - 25ms/epoch - 2ms/step\n",
      "Epoch 134/300\n",
      "16/16 - 0s - loss: 0.0373 - acc: 0.9902 - mae: 0.0139 - 27ms/epoch - 2ms/step\n",
      "Epoch 135/300\n",
      "16/16 - 0s - loss: 0.0365 - acc: 0.9883 - mae: 0.0143 - 27ms/epoch - 2ms/step\n",
      "Epoch 136/300\n",
      "16/16 - 0s - loss: 0.0371 - acc: 0.9883 - mae: 0.0145 - 23ms/epoch - 1ms/step\n",
      "Epoch 137/300\n",
      "16/16 - 0s - loss: 0.0388 - acc: 0.9902 - mae: 0.0164 - 23ms/epoch - 1ms/step\n",
      "Epoch 138/300\n",
      "16/16 - 0s - loss: 0.0390 - acc: 0.9883 - mae: 0.0152 - 21ms/epoch - 1ms/step\n",
      "Epoch 139/300\n",
      "16/16 - 0s - loss: 0.0367 - acc: 0.9863 - mae: 0.0151 - 21ms/epoch - 1ms/step\n",
      "Epoch 140/300\n",
      "16/16 - 0s - loss: 0.0357 - acc: 0.9902 - mae: 0.0139 - 22ms/epoch - 1ms/step\n",
      "Epoch 141/300\n",
      "16/16 - 0s - loss: 0.0372 - acc: 0.9883 - mae: 0.0158 - 20ms/epoch - 1ms/step\n",
      "Epoch 142/300\n",
      "16/16 - 0s - loss: 0.0377 - acc: 0.9844 - mae: 0.0165 - 21ms/epoch - 1ms/step\n",
      "Epoch 143/300\n",
      "16/16 - 0s - loss: 0.0386 - acc: 0.9902 - mae: 0.0152 - 26ms/epoch - 2ms/step\n",
      "Epoch 144/300\n",
      "16/16 - 0s - loss: 0.0358 - acc: 0.9883 - mae: 0.0146 - 25ms/epoch - 2ms/step\n",
      "Epoch 145/300\n",
      "16/16 - 0s - loss: 0.0344 - acc: 0.9883 - mae: 0.0134 - 21ms/epoch - 1ms/step\n",
      "Epoch 146/300\n",
      "16/16 - 0s - loss: 0.0341 - acc: 0.9902 - mae: 0.0139 - 19ms/epoch - 1ms/step\n",
      "Epoch 147/300\n",
      "16/16 - 0s - loss: 0.0365 - acc: 0.9844 - mae: 0.0158 - 18ms/epoch - 1ms/step\n",
      "Epoch 148/300\n",
      "16/16 - 0s - loss: 0.0386 - acc: 0.9883 - mae: 0.0170 - 25ms/epoch - 2ms/step\n",
      "Epoch 149/300\n",
      "16/16 - 0s - loss: 0.0370 - acc: 0.9883 - mae: 0.0159 - 22ms/epoch - 1ms/step\n",
      "Epoch 150/300\n",
      "16/16 - 0s - loss: 0.0354 - acc: 0.9844 - mae: 0.0159 - 23ms/epoch - 1ms/step\n",
      "Epoch 151/300\n",
      "16/16 - 0s - loss: 0.0331 - acc: 0.9902 - mae: 0.0140 - 22ms/epoch - 1ms/step\n",
      "Epoch 152/300\n",
      "16/16 - 0s - loss: 0.0407 - acc: 0.9863 - mae: 0.0165 - 25ms/epoch - 2ms/step\n",
      "Epoch 153/300\n",
      "16/16 - 0s - loss: 0.0443 - acc: 0.9785 - mae: 0.0200 - 26ms/epoch - 2ms/step\n",
      "Epoch 154/300\n",
      "16/16 - 0s - loss: 0.0397 - acc: 0.9824 - mae: 0.0182 - 24ms/epoch - 2ms/step\n",
      "Epoch 155/300\n",
      "16/16 - 0s - loss: 0.0341 - acc: 0.9902 - mae: 0.0136 - 20ms/epoch - 1ms/step\n",
      "Epoch 156/300\n",
      "16/16 - 0s - loss: 0.0319 - acc: 0.9883 - mae: 0.0136 - 23ms/epoch - 1ms/step\n",
      "Epoch 157/300\n",
      "16/16 - 0s - loss: 0.0310 - acc: 0.9902 - mae: 0.0128 - 22ms/epoch - 1ms/step\n",
      "Epoch 158/300\n",
      "16/16 - 0s - loss: 0.0377 - acc: 0.9844 - mae: 0.0180 - 24ms/epoch - 2ms/step\n",
      "Epoch 159/300\n",
      "16/16 - 0s - loss: 0.0325 - acc: 0.9863 - mae: 0.0142 - 24ms/epoch - 2ms/step\n",
      "Epoch 160/300\n",
      "16/16 - 0s - loss: 0.0351 - acc: 0.9902 - mae: 0.0141 - 25ms/epoch - 2ms/step\n",
      "Epoch 161/300\n",
      "16/16 - 0s - loss: 0.0308 - acc: 0.9902 - mae: 0.0127 - 21ms/epoch - 1ms/step\n",
      "Epoch 162/300\n",
      "16/16 - 0s - loss: 0.0295 - acc: 0.9902 - mae: 0.0124 - 26ms/epoch - 2ms/step\n",
      "Epoch 163/300\n",
      "16/16 - 0s - loss: 0.0296 - acc: 0.9902 - mae: 0.0122 - 23ms/epoch - 1ms/step\n",
      "Epoch 164/300\n",
      "16/16 - 0s - loss: 0.0295 - acc: 0.9902 - mae: 0.0127 - 24ms/epoch - 2ms/step\n",
      "Epoch 165/300\n",
      "16/16 - 0s - loss: 0.0289 - acc: 0.9902 - mae: 0.0118 - 28ms/epoch - 2ms/step\n",
      "Epoch 166/300\n",
      "16/16 - 0s - loss: 0.0302 - acc: 0.9863 - mae: 0.0143 - 23ms/epoch - 1ms/step\n",
      "Epoch 167/300\n",
      "16/16 - 0s - loss: 0.0340 - acc: 0.9863 - mae: 0.0162 - 26ms/epoch - 2ms/step\n",
      "Epoch 168/300\n",
      "16/16 - 0s - loss: 0.0279 - acc: 0.9883 - mae: 0.0124 - 27ms/epoch - 2ms/step\n",
      "Epoch 169/300\n",
      "16/16 - 0s - loss: 0.0298 - acc: 0.9863 - mae: 0.0140 - 26ms/epoch - 2ms/step\n",
      "Epoch 170/300\n",
      "16/16 - 0s - loss: 0.0298 - acc: 0.9902 - mae: 0.0129 - 25ms/epoch - 2ms/step\n",
      "Epoch 171/300\n",
      "16/16 - 0s - loss: 0.0281 - acc: 0.9902 - mae: 0.0124 - 26ms/epoch - 2ms/step\n",
      "Epoch 172/300\n",
      "16/16 - 0s - loss: 0.0278 - acc: 0.9902 - mae: 0.0123 - 25ms/epoch - 2ms/step\n",
      "Epoch 173/300\n",
      "16/16 - 0s - loss: 0.0272 - acc: 0.9902 - mae: 0.0119 - 24ms/epoch - 2ms/step\n",
      "Epoch 174/300\n",
      "16/16 - 0s - loss: 0.0297 - acc: 0.9883 - mae: 0.0139 - 21ms/epoch - 1ms/step\n",
      "Epoch 175/300\n",
      "16/16 - 0s - loss: 0.0273 - acc: 0.9902 - mae: 0.0118 - 25ms/epoch - 2ms/step\n",
      "Epoch 176/300\n",
      "16/16 - 0s - loss: 0.0275 - acc: 0.9883 - mae: 0.0121 - 25ms/epoch - 2ms/step\n",
      "Epoch 177/300\n",
      "16/16 - 0s - loss: 0.0257 - acc: 0.9902 - mae: 0.0109 - 26ms/epoch - 2ms/step\n",
      "Epoch 178/300\n",
      "16/16 - 0s - loss: 0.0276 - acc: 0.9922 - mae: 0.0113 - 29ms/epoch - 2ms/step\n",
      "Epoch 179/300\n",
      "16/16 - 0s - loss: 0.0268 - acc: 0.9902 - mae: 0.0119 - 30ms/epoch - 2ms/step\n",
      "Epoch 180/300\n",
      "16/16 - 0s - loss: 0.0263 - acc: 0.9922 - mae: 0.0125 - 28ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "16/16 - 0s - loss: 0.0258 - acc: 0.9883 - mae: 0.0127 - 23ms/epoch - 1ms/step\n",
      "Epoch 182/300\n",
      "16/16 - 0s - loss: 0.0274 - acc: 0.9883 - mae: 0.0125 - 24ms/epoch - 2ms/step\n",
      "Epoch 183/300\n",
      "16/16 - 0s - loss: 0.0303 - acc: 0.9863 - mae: 0.0136 - 25ms/epoch - 2ms/step\n",
      "Epoch 184/300\n",
      "16/16 - 0s - loss: 0.0271 - acc: 0.9902 - mae: 0.0124 - 18ms/epoch - 1ms/step\n",
      "Epoch 185/300\n",
      "16/16 - 0s - loss: 0.0249 - acc: 0.9883 - mae: 0.0116 - 21ms/epoch - 1ms/step\n",
      "Epoch 186/300\n",
      "16/16 - 0s - loss: 0.0240 - acc: 0.9883 - mae: 0.0107 - 23ms/epoch - 1ms/step\n",
      "Epoch 187/300\n",
      "16/16 - 0s - loss: 0.0291 - acc: 0.9902 - mae: 0.0127 - 22ms/epoch - 1ms/step\n",
      "Epoch 188/300\n",
      "16/16 - 0s - loss: 0.0249 - acc: 0.9922 - mae: 0.0105 - 24ms/epoch - 1ms/step\n",
      "Epoch 189/300\n",
      "16/16 - 0s - loss: 0.0232 - acc: 0.9902 - mae: 0.0107 - 27ms/epoch - 2ms/step\n",
      "Epoch 190/300\n",
      "16/16 - 0s - loss: 0.0237 - acc: 0.9922 - mae: 0.0099 - 24ms/epoch - 1ms/step\n",
      "Epoch 191/300\n",
      "16/16 - 0s - loss: 0.0231 - acc: 0.9922 - mae: 0.0107 - 20ms/epoch - 1ms/step\n",
      "Epoch 192/300\n",
      "16/16 - 0s - loss: 0.0242 - acc: 0.9883 - mae: 0.0112 - 21ms/epoch - 1ms/step\n",
      "Epoch 193/300\n",
      "16/16 - 0s - loss: 0.0258 - acc: 0.9922 - mae: 0.0127 - 17ms/epoch - 1ms/step\n",
      "Epoch 194/300\n",
      "16/16 - 0s - loss: 0.0243 - acc: 0.9941 - mae: 0.0105 - 18ms/epoch - 1ms/step\n",
      "Epoch 195/300\n",
      "16/16 - 0s - loss: 0.0222 - acc: 0.9902 - mae: 0.0102 - 19ms/epoch - 1ms/step\n",
      "Epoch 196/300\n",
      "16/16 - 0s - loss: 0.0222 - acc: 0.9902 - mae: 0.0101 - 23ms/epoch - 1ms/step\n",
      "Epoch 197/300\n",
      "16/16 - 0s - loss: 0.0250 - acc: 0.9902 - mae: 0.0128 - 26ms/epoch - 2ms/step\n",
      "Epoch 198/300\n",
      "16/16 - 0s - loss: 0.0450 - acc: 0.9785 - mae: 0.0224 - 26ms/epoch - 2ms/step\n",
      "Epoch 199/300\n",
      "16/16 - 0s - loss: 0.0238 - acc: 0.9922 - mae: 0.0108 - 24ms/epoch - 2ms/step\n",
      "Epoch 200/300\n",
      "16/16 - 0s - loss: 0.0245 - acc: 0.9902 - mae: 0.0112 - 24ms/epoch - 2ms/step\n",
      "Epoch 201/300\n",
      "16/16 - 0s - loss: 0.0228 - acc: 0.9902 - mae: 0.0103 - 22ms/epoch - 1ms/step\n",
      "Epoch 202/300\n",
      "16/16 - 0s - loss: 0.0211 - acc: 0.9922 - mae: 0.0094 - 25ms/epoch - 2ms/step\n",
      "Epoch 203/300\n",
      "16/16 - 0s - loss: 0.0230 - acc: 0.9883 - mae: 0.0111 - 22ms/epoch - 1ms/step\n",
      "Epoch 204/300\n",
      "16/16 - 0s - loss: 0.0247 - acc: 0.9902 - mae: 0.0112 - 23ms/epoch - 1ms/step\n",
      "Epoch 205/300\n",
      "16/16 - 0s - loss: 0.0200 - acc: 0.9922 - mae: 0.0083 - 25ms/epoch - 2ms/step\n",
      "Epoch 206/300\n",
      "16/16 - 0s - loss: 0.0209 - acc: 0.9941 - mae: 0.0091 - 25ms/epoch - 2ms/step\n",
      "Epoch 207/300\n",
      "16/16 - 0s - loss: 0.0196 - acc: 0.9961 - mae: 0.0077 - 22ms/epoch - 1ms/step\n",
      "Epoch 208/300\n",
      "16/16 - 0s - loss: 0.0215 - acc: 0.9922 - mae: 0.0107 - 25ms/epoch - 2ms/step\n",
      "Epoch 209/300\n",
      "16/16 - 0s - loss: 0.0214 - acc: 0.9941 - mae: 0.0095 - 25ms/epoch - 2ms/step\n",
      "Epoch 210/300\n",
      "16/16 - 0s - loss: 0.0213 - acc: 0.9902 - mae: 0.0100 - 23ms/epoch - 1ms/step\n",
      "Epoch 211/300\n",
      "16/16 - 0s - loss: 0.0195 - acc: 0.9961 - mae: 0.0082 - 20ms/epoch - 1ms/step\n",
      "Epoch 212/300\n",
      "16/16 - 0s - loss: 0.0185 - acc: 0.9922 - mae: 0.0087 - 19ms/epoch - 1ms/step\n",
      "Epoch 213/300\n",
      "16/16 - 0s - loss: 0.0236 - acc: 0.9922 - mae: 0.0112 - 19ms/epoch - 1ms/step\n",
      "Epoch 214/300\n",
      "16/16 - 0s - loss: 0.0204 - acc: 0.9941 - mae: 0.0091 - 23ms/epoch - 1ms/step\n",
      "Epoch 215/300\n",
      "16/16 - 0s - loss: 0.0185 - acc: 0.9922 - mae: 0.0079 - 20ms/epoch - 1ms/step\n",
      "Epoch 216/300\n",
      "16/16 - 0s - loss: 0.0179 - acc: 0.9941 - mae: 0.0075 - 21ms/epoch - 1ms/step\n",
      "Epoch 217/300\n",
      "16/16 - 0s - loss: 0.0177 - acc: 0.9941 - mae: 0.0078 - 27ms/epoch - 2ms/step\n",
      "Epoch 218/300\n",
      "16/16 - 0s - loss: 0.0195 - acc: 0.9941 - mae: 0.0089 - 25ms/epoch - 2ms/step\n",
      "Epoch 219/300\n",
      "16/16 - 0s - loss: 0.0169 - acc: 0.9922 - mae: 0.0075 - 24ms/epoch - 1ms/step\n",
      "Epoch 220/300\n",
      "16/16 - 0s - loss: 0.0191 - acc: 0.9922 - mae: 0.0081 - 23ms/epoch - 1ms/step\n",
      "Epoch 221/300\n",
      "16/16 - 0s - loss: 0.0182 - acc: 0.9941 - mae: 0.0077 - 24ms/epoch - 2ms/step\n",
      "Epoch 222/300\n",
      "16/16 - 0s - loss: 0.0162 - acc: 0.9941 - mae: 0.0070 - 25ms/epoch - 2ms/step\n",
      "Epoch 223/300\n",
      "16/16 - 0s - loss: 0.0185 - acc: 0.9922 - mae: 0.0084 - 26ms/epoch - 2ms/step\n",
      "Epoch 224/300\n",
      "16/16 - 0s - loss: 0.0170 - acc: 0.9941 - mae: 0.0076 - 20ms/epoch - 1ms/step\n",
      "Epoch 225/300\n",
      "16/16 - 0s - loss: 0.0162 - acc: 0.9980 - mae: 0.0062 - 21ms/epoch - 1ms/step\n",
      "Epoch 226/300\n",
      "16/16 - 0s - loss: 0.0210 - acc: 0.9922 - mae: 0.0096 - 20ms/epoch - 1ms/step\n",
      "Epoch 227/300\n",
      "16/16 - 0s - loss: 0.0162 - acc: 0.9961 - mae: 0.0066 - 23ms/epoch - 1ms/step\n",
      "Epoch 228/300\n",
      "16/16 - 0s - loss: 0.0163 - acc: 0.9941 - mae: 0.0071 - 22ms/epoch - 1ms/step\n",
      "Epoch 229/300\n",
      "16/16 - 0s - loss: 0.0167 - acc: 0.9922 - mae: 0.0074 - 24ms/epoch - 2ms/step\n",
      "Epoch 230/300\n",
      "16/16 - 0s - loss: 0.0162 - acc: 0.9941 - mae: 0.0070 - 25ms/epoch - 2ms/step\n",
      "Epoch 231/300\n",
      "16/16 - 0s - loss: 0.0159 - acc: 0.9941 - mae: 0.0069 - 21ms/epoch - 1ms/step\n",
      "Epoch 232/300\n",
      "16/16 - 0s - loss: 0.0157 - acc: 0.9941 - mae: 0.0067 - 22ms/epoch - 1ms/step\n",
      "Epoch 233/300\n",
      "16/16 - 0s - loss: 0.0189 - acc: 0.9922 - mae: 0.0087 - 18ms/epoch - 1ms/step\n",
      "Epoch 234/300\n",
      "16/16 - 0s - loss: 0.0188 - acc: 0.9922 - mae: 0.0085 - 21ms/epoch - 1ms/step\n",
      "Epoch 235/300\n",
      "16/16 - 0s - loss: 0.0148 - acc: 0.9980 - mae: 0.0057 - 22ms/epoch - 1ms/step\n",
      "Epoch 236/300\n",
      "16/16 - 0s - loss: 0.0176 - acc: 0.9941 - mae: 0.0075 - 22ms/epoch - 1ms/step\n",
      "Epoch 237/300\n",
      "16/16 - 0s - loss: 0.0166 - acc: 0.9941 - mae: 0.0073 - 23ms/epoch - 1ms/step\n",
      "Epoch 238/300\n",
      "16/16 - 0s - loss: 0.0166 - acc: 0.9922 - mae: 0.0077 - 26ms/epoch - 2ms/step\n",
      "Epoch 239/300\n",
      "16/16 - 0s - loss: 0.0153 - acc: 0.9941 - mae: 0.0069 - 23ms/epoch - 1ms/step\n",
      "Epoch 240/300\n",
      "16/16 - 0s - loss: 0.0159 - acc: 0.9961 - mae: 0.0066 - 23ms/epoch - 1ms/step\n",
      "Epoch 241/300\n",
      "16/16 - 0s - loss: 0.0141 - acc: 0.9961 - mae: 0.0060 - 22ms/epoch - 1ms/step\n",
      "Epoch 242/300\n",
      "16/16 - 0s - loss: 0.0159 - acc: 0.9980 - mae: 0.0060 - 24ms/epoch - 2ms/step\n",
      "Epoch 243/300\n",
      "16/16 - 0s - loss: 0.0139 - acc: 0.9961 - mae: 0.0061 - 25ms/epoch - 2ms/step\n",
      "Epoch 244/300\n",
      "16/16 - 0s - loss: 0.0150 - acc: 0.9961 - mae: 0.0066 - 25ms/epoch - 2ms/step\n",
      "Epoch 245/300\n",
      "16/16 - 0s - loss: 0.0142 - acc: 0.9922 - mae: 0.0062 - 25ms/epoch - 2ms/step\n",
      "Epoch 246/300\n",
      "16/16 - 0s - loss: 0.0148 - acc: 0.9961 - mae: 0.0067 - 24ms/epoch - 1ms/step\n",
      "Epoch 247/300\n",
      "16/16 - 0s - loss: 0.0150 - acc: 0.9941 - mae: 0.0070 - 23ms/epoch - 1ms/step\n",
      "Epoch 248/300\n",
      "16/16 - 0s - loss: 0.0192 - acc: 0.9922 - mae: 0.0095 - 24ms/epoch - 1ms/step\n",
      "Epoch 249/300\n",
      "16/16 - 0s - loss: 0.0125 - acc: 0.9961 - mae: 0.0049 - 22ms/epoch - 1ms/step\n",
      "Epoch 250/300\n",
      "16/16 - 0s - loss: 0.0156 - acc: 0.9980 - mae: 0.0065 - 26ms/epoch - 2ms/step\n",
      "Epoch 251/300\n",
      "16/16 - 0s - loss: 0.0130 - acc: 0.9961 - mae: 0.0048 - 26ms/epoch - 2ms/step\n",
      "Epoch 252/300\n",
      "16/16 - 0s - loss: 0.0134 - acc: 0.9961 - mae: 0.0056 - 26ms/epoch - 2ms/step\n",
      "Epoch 253/300\n",
      "16/16 - 0s - loss: 0.0126 - acc: 0.9961 - mae: 0.0046 - 23ms/epoch - 1ms/step\n",
      "Epoch 254/300\n",
      "16/16 - 0s - loss: 0.0127 - acc: 0.9961 - mae: 0.0052 - 23ms/epoch - 1ms/step\n",
      "Epoch 255/300\n",
      "16/16 - 0s - loss: 0.0121 - acc: 0.9980 - mae: 0.0048 - 21ms/epoch - 1ms/step\n",
      "Epoch 256/300\n",
      "16/16 - 0s - loss: 0.0125 - acc: 0.9961 - mae: 0.0048 - 21ms/epoch - 1ms/step\n",
      "Epoch 257/300\n",
      "16/16 - 0s - loss: 0.0142 - acc: 0.9980 - mae: 0.0051 - 25ms/epoch - 2ms/step\n",
      "Epoch 258/300\n",
      "16/16 - 0s - loss: 0.0118 - acc: 0.9980 - mae: 0.0047 - 28ms/epoch - 2ms/step\n",
      "Epoch 259/300\n",
      "16/16 - 0s - loss: 0.0146 - acc: 0.9941 - mae: 0.0066 - 27ms/epoch - 2ms/step\n",
      "Epoch 260/300\n",
      "16/16 - 0s - loss: 0.0160 - acc: 0.9961 - mae: 0.0074 - 28ms/epoch - 2ms/step\n",
      "Epoch 261/300\n",
      "16/16 - 0s - loss: 0.0128 - acc: 0.9961 - mae: 0.0048 - 25ms/epoch - 2ms/step\n",
      "Epoch 262/300\n",
      "16/16 - 0s - loss: 0.0120 - acc: 0.9961 - mae: 0.0051 - 24ms/epoch - 2ms/step\n",
      "Epoch 263/300\n",
      "16/16 - 0s - loss: 0.0123 - acc: 0.9941 - mae: 0.0052 - 23ms/epoch - 1ms/step\n",
      "Epoch 264/300\n",
      "16/16 - 0s - loss: 0.0134 - acc: 0.9941 - mae: 0.0060 - 21ms/epoch - 1ms/step\n",
      "Epoch 265/300\n",
      "16/16 - 0s - loss: 0.0112 - acc: 0.9980 - mae: 0.0042 - 25ms/epoch - 2ms/step\n",
      "Epoch 266/300\n",
      "16/16 - 0s - loss: 0.0147 - acc: 0.9941 - mae: 0.0069 - 27ms/epoch - 2ms/step\n",
      "Epoch 267/300\n",
      "16/16 - 0s - loss: 0.0230 - acc: 0.9883 - mae: 0.0119 - 27ms/epoch - 2ms/step\n",
      "Epoch 268/300\n",
      "16/16 - 0s - loss: 0.0124 - acc: 0.9980 - mae: 0.0044 - 24ms/epoch - 2ms/step\n",
      "Epoch 269/300\n",
      "16/16 - 0s - loss: 0.0122 - acc: 0.9980 - mae: 0.0043 - 23ms/epoch - 1ms/step\n",
      "Epoch 270/300\n",
      "16/16 - 0s - loss: 0.0184 - acc: 0.9902 - mae: 0.0092 - 24ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/300\n",
      "16/16 - 0s - loss: 0.0112 - acc: 0.9980 - mae: 0.0047 - 26ms/epoch - 2ms/step\n",
      "Epoch 272/300\n",
      "16/16 - 0s - loss: 0.0106 - acc: 0.9980 - mae: 0.0039 - 26ms/epoch - 2ms/step\n",
      "Epoch 273/300\n",
      "16/16 - 0s - loss: 0.0114 - acc: 0.9980 - mae: 0.0043 - 25ms/epoch - 2ms/step\n",
      "Epoch 274/300\n",
      "16/16 - 0s - loss: 0.0115 - acc: 0.9980 - mae: 0.0045 - 27ms/epoch - 2ms/step\n",
      "Epoch 275/300\n",
      "16/16 - 0s - loss: 0.0102 - acc: 0.9980 - mae: 0.0039 - 23ms/epoch - 1ms/step\n",
      "Epoch 276/300\n",
      "16/16 - 0s - loss: 0.0102 - acc: 0.9980 - mae: 0.0035 - 25ms/epoch - 2ms/step\n",
      "Epoch 277/300\n",
      "16/16 - 0s - loss: 0.0114 - acc: 0.9961 - mae: 0.0044 - 22ms/epoch - 1ms/step\n",
      "Epoch 278/300\n",
      "16/16 - 0s - loss: 0.0123 - acc: 0.9961 - mae: 0.0054 - 23ms/epoch - 1ms/step\n",
      "Epoch 279/300\n",
      "16/16 - 0s - loss: 0.0171 - acc: 0.9922 - mae: 0.0082 - 26ms/epoch - 2ms/step\n",
      "Epoch 280/300\n",
      "16/16 - 0s - loss: 0.0220 - acc: 0.9922 - mae: 0.0110 - 22ms/epoch - 1ms/step\n",
      "Epoch 281/300\n",
      "16/16 - 0s - loss: 0.0126 - acc: 0.9980 - mae: 0.0050 - 25ms/epoch - 2ms/step\n",
      "Epoch 282/300\n",
      "16/16 - 0s - loss: 0.0125 - acc: 0.9961 - mae: 0.0051 - 24ms/epoch - 2ms/step\n",
      "Epoch 283/300\n",
      "16/16 - 0s - loss: 0.0112 - acc: 0.9980 - mae: 0.0044 - 24ms/epoch - 1ms/step\n",
      "Epoch 284/300\n",
      "16/16 - 0s - loss: 0.0094 - acc: 1.0000 - mae: 0.0035 - 25ms/epoch - 2ms/step\n",
      "Epoch 285/300\n",
      "16/16 - 0s - loss: 0.0106 - acc: 1.0000 - mae: 0.0040 - 25ms/epoch - 2ms/step\n",
      "Epoch 286/300\n",
      "16/16 - 0s - loss: 0.0113 - acc: 0.9961 - mae: 0.0048 - 23ms/epoch - 1ms/step\n",
      "Epoch 287/300\n",
      "16/16 - 0s - loss: 0.0134 - acc: 0.9941 - mae: 0.0066 - 25ms/epoch - 2ms/step\n",
      "Epoch 288/300\n",
      "16/16 - 0s - loss: 0.0103 - acc: 1.0000 - mae: 0.0033 - 21ms/epoch - 1ms/step\n",
      "Epoch 289/300\n",
      "16/16 - 0s - loss: 0.0096 - acc: 0.9980 - mae: 0.0037 - 25ms/epoch - 2ms/step\n",
      "Epoch 290/300\n",
      "16/16 - 0s - loss: 0.0092 - acc: 1.0000 - mae: 0.0033 - 27ms/epoch - 2ms/step\n",
      "Epoch 291/300\n",
      "16/16 - 0s - loss: 0.0096 - acc: 0.9961 - mae: 0.0036 - 27ms/epoch - 2ms/step\n",
      "Epoch 292/300\n",
      "16/16 - 0s - loss: 0.0103 - acc: 1.0000 - mae: 0.0032 - 24ms/epoch - 2ms/step\n",
      "Epoch 293/300\n",
      "16/16 - 0s - loss: 0.0161 - acc: 0.9941 - mae: 0.0071 - 24ms/epoch - 2ms/step\n",
      "Epoch 294/300\n",
      "16/16 - 0s - loss: 0.0083 - acc: 0.9980 - mae: 0.0025 - 23ms/epoch - 1ms/step\n",
      "Epoch 295/300\n",
      "16/16 - 0s - loss: 0.0133 - acc: 0.9941 - mae: 0.0062 - 21ms/epoch - 1ms/step\n",
      "Epoch 296/300\n",
      "16/16 - 0s - loss: 0.0096 - acc: 0.9961 - mae: 0.0042 - 23ms/epoch - 1ms/step\n",
      "Epoch 297/300\n",
      "16/16 - 0s - loss: 0.0090 - acc: 1.0000 - mae: 0.0031 - 25ms/epoch - 2ms/step\n",
      "Epoch 298/300\n",
      "16/16 - 0s - loss: 0.0089 - acc: 1.0000 - mae: 0.0024 - 23ms/epoch - 1ms/step\n",
      "Epoch 299/300\n",
      "16/16 - 0s - loss: 0.0121 - acc: 0.9961 - mae: 0.0058 - 22ms/epoch - 1ms/step\n",
      "Epoch 300/300\n",
      "16/16 - 0s - loss: 0.0203 - acc: 0.9902 - mae: 0.0105 - 24ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x206eea96040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=300, batch_size=32, verbose=2)\n",
    "history #401번 돌림0.8997 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87fcd638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0210 - acc: 1.0000 - mae: 0.0095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.021039623767137527, 1.0, 0.009467021562159061]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eva_test=model.evaluate(X_test, y_test)\n",
    "eva_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "448622c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.0104066e-08],\n",
       "       [1.0000000e+00, 5.5570113e-09],\n",
       "       [1.0000000e+00, 6.6398065e-09],\n",
       "       [1.0000000e+00, 5.5584106e-09],\n",
       "       [1.0000000e+00, 5.6710139e-09]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "pred_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0992ceb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bbae053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9810937570886302"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, confusion_matrix\n",
    "R2 = r2_score(y_test, pred_test, multioutput='variance_weighted')\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4933c",
   "metadata": {},
   "source": [
    "#### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "507f723b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1=np.argmax(y_test, axis=-1)#1차원 배열로만들어주어야함\n",
    "y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a51f573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_test=np.argmax(pred_test, axis=-1)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98549403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0],\n",
       "       [ 0, 41]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix= confusion_matrix(y_test1, Y_pred_test)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62e6387f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m cmap\u001b[38;5;241m=\u001b[39m\u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mGreens\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(conf_matrix, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mcmap)  \u001b[38;5;66;03m# , cmap=plt.cm.Greens\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "title = 'test'\n",
    "cmap=plt.cm.Greens\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=cmap)  # , cmap=plt.cm.Greens\n",
    "plt.title(title, size=12)\n",
    "plt.colorbar(fraction=0.05, pad=0.05)\n",
    "tick_marks = np.arange(3, 3)\n",
    "plt.xticks(np.arange(3), ('0', '1', '2'))\n",
    "plt.yticks(np.arange(3), ('0', '1', '2'))\n",
    "\n",
    "\n",
    "fmt = 'd' \n",
    "thresh = 1\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], fmt),\n",
    "                 ha=\"center\", va=\"center\", color=\"white\" if conf_matrix[i, j] > thresh else \"black\")  #horizontalalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_test1,marker = 'o',label='realY')\n",
    "plt.plot(Y_pred_test,marker = 'o',label='predictY')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f45a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d0cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa1c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
